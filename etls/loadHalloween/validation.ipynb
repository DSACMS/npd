{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a26a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dbHelpers import createEngine\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f9d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = createEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../scratch/halloween_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d13c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_state_df = pd.read_sql('select * from npd.fips_state', con = engine)\n",
    "fips_state_df.set_index('abbreviation', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96301a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_or_load(df, table_name, schema_name, load=False):\n",
    "    if load:\n",
    "        df.to_sql(table_name, schema = schema_name, con = engine)\n",
    "    else:\n",
    "        df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f97bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_to_bool = {1: True, 0: False}\n",
    "\n",
    "\n",
    "def convertBool(val):\n",
    "    if val in primary_to_bool.keys():\n",
    "        return primary_to_bool[val]\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/2424709856.py:5: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,f))\n"
     ]
    }
   ],
   "source": [
    "df_dict={}\n",
    "for f in os.listdir(path):\n",
    "    if '.csv' in f:\n",
    "        tablename = f.split('.csv')[0]\n",
    "        df = pd.read_csv(os.path.join(path,f))\n",
    "        df_dict[f]=df\n",
    "        df, tablename, index=False, schema = 'raw_csv', con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e520af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/2346510260.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  npi1['entity_type_code'] = 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['individual_id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m merged_taxonomy_df[\u001b[33m'\u001b[39m\u001b[33mstate_code\u001b[39m\u001b[33m'\u001b[39m] = merged_taxonomy_df[\u001b[33m'\u001b[39m\u001b[33mstate_code\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: fips_state_df.loc[x][\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     11\u001b[39m merged_taxonomy_df.rename(columns={\u001b[33m'\u001b[39m\u001b[33mid_individual\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mindividual_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtaxonomy_code\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mnucc_code\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m provider_to_taxonomy_df = \u001b[43mmerged_taxonomy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mindividual_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnucc_code\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mis_primary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m provider_to_taxonomy_df[\u001b[33m'\u001b[39m\u001b[33mis_primary\u001b[39m\u001b[33m'\u001b[39m] = provider_to_taxonomy_df[\u001b[33m'\u001b[39m\u001b[33mis_primary\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: convertBool(x))\n\u001b[32m     14\u001b[39m dedup_taxonomy_df = provider_to_taxonomy_df.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mis_primary\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)[\n\u001b[32m     15\u001b[39m         [\u001b[33m'\u001b[39m\u001b[33mindividual_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnucc_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mis_primary\u001b[39m\u001b[33m'\u001b[39m]].drop_duplicates(subset=[\u001b[33m'\u001b[39m\u001b[33mnucc_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mindividual_id\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['individual_id'] not in index\""
     ]
    }
   ],
   "source": [
    "practitioner_df = df_dict['practitioner.csv']\n",
    "#note: we can do this because each practitioner only appears once in this table\n",
    "practitioner_df['id'] = [uuid.uuid4() for i in practitioner_df.index]\n",
    "practitioner_df.rename(columns = {'gender_code': 'sex', 'name_prefix': 'prefix', 'name_suffix': 'suffix'}, inplace=True)\n",
    "npi1 = practitioner_df[['npi']]\n",
    "npi1['entity_type_code'] = 1\n",
    "practitioner_taxonomy_df = df_dict['practitionerrole.csv']\n",
    "merged_taxonomy_df = practitioner_taxonomy_df.merge(practitioner_df, left_on = 'practitioner_id', right_on = 'npi', suffixes = ('tax', 'individual')) \n",
    "merged_taxonomy_df = merged_taxonomy_df.loc[merged_taxonomy_df['state_code']!='ZZ']\n",
    "merged_taxonomy_df['state_code'] = merged_taxonomy_df['state_code'].apply(lambda x: fips_state_df.loc[x]['id'])\n",
    "merged_taxonomy_df.rename(columns={'idindividual': 'individual_id', 'taxonomy_code':'nucc_code'}, inplace=True)\n",
    "provider_to_taxonomy_df = merged_taxonomy_df[['individual_id', 'nucc_code', 'is_primary']]\n",
    "provider_to_taxonomy_df['is_primary'] = provider_to_taxonomy_df['is_primary'].apply(lambda x: convertBool(x))\n",
    "dedup_taxonomy_df = provider_to_taxonomy_df.sort_values(by='is_primary', ascending=False)[\n",
    "        ['individual_id', 'nucc_code', 'is_primary']].drop_duplicates(subset=['nucc_code', 'individual_id'])\n",
    "dedup_taxonomy_df['id'] = [uuid.uuid4() for i in dedup_taxonomy_df.index]\n",
    "credential_df = provider_to_taxonomy_df.merge(dedup_taxonomy_df, on = ['individual_id', 'nucc_code'], suffixes = ('tax', 'cred'))\n",
    "credential_df.rename(columns={'idtax': 'provider_to_taxonomy_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31d3500d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idtax</th>\n",
       "      <th>practitioner_id</th>\n",
       "      <th>nucc_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>license_number</th>\n",
       "      <th>is_primary</th>\n",
       "      <th>npi</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>prefix</th>\n",
       "      <th>suffix</th>\n",
       "      <th>credential_text</th>\n",
       "      <th>is_sole_proprietor</th>\n",
       "      <th>sex</th>\n",
       "      <th>13872713232</th>\n",
       "      <th>idindividual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1487102463</td>\n",
       "      <td>103T00000X</td>\n",
       "      <td>20</td>\n",
       "      <td>2744</td>\n",
       "      <td>0</td>\n",
       "      <td>1487102463</td>\n",
       "      <td>FINLEY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LPC</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>31c1b247-83da-440a-bc7a-2673f1591bcd</td>\n",
       "      <td>3723eac5-b768-4444-bd71-c7bbcc1aba4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1033667035</td>\n",
       "      <td>2255A2300X</td>\n",
       "      <td>42</td>\n",
       "      <td>RT006860</td>\n",
       "      <td>1</td>\n",
       "      <td>1033667035</td>\n",
       "      <td>OXLEY</td>\n",
       "      <td>MEGAN</td>\n",
       "      <td>FRANCES</td>\n",
       "      <td>MS.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M.ED., LAT, ATC</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>bcf58541-7423-4597-8a03-409ddfba52a5</td>\n",
       "      <td>b3e06dd5-a15b-49f4-a0e7-d630638841ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1225586258</td>\n",
       "      <td>207Q00000X</td>\n",
       "      <td>41</td>\n",
       "      <td>PA190185</td>\n",
       "      <td>1</td>\n",
       "      <td>1225586258</td>\n",
       "      <td>SISNEROS</td>\n",
       "      <td>CONTESSA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PA-C</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>83241ffe-6823-4ba1-812b-2e88ca3bc8e8</td>\n",
       "      <td>8f61bd63-b033-4feb-a628-ed9cd87c260e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>1790233658</td>\n",
       "      <td>208100000X</td>\n",
       "      <td>26</td>\n",
       "      <td>5501017928</td>\n",
       "      <td>1</td>\n",
       "      <td>1790233658</td>\n",
       "      <td>SCHLEMMER</td>\n",
       "      <td>AMBER</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DPT</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>faa6fa37-e51d-4cf8-86e1-134775d16ba3</td>\n",
       "      <td>9d1a3887-2482-410f-a4db-d5a2378d9abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>1316495229</td>\n",
       "      <td>174H00000X</td>\n",
       "      <td>13</td>\n",
       "      <td>2013-211</td>\n",
       "      <td>1</td>\n",
       "      <td>1316495229</td>\n",
       "      <td>TERRY</td>\n",
       "      <td>KATIE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLD</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>c5e07e17-22cc-4c57-9150-10d85390e296</td>\n",
       "      <td>6a281cb1-a4e3-4403-b04a-806c5163de1e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idtax  practitioner_id   nucc_code state_code license_number  is_primary  \\\n",
       "0      3       1487102463  103T00000X         20           2744           0   \n",
       "1     11       1033667035  2255A2300X         42       RT006860           1   \n",
       "2     50       1225586258  207Q00000X         41       PA190185           1   \n",
       "3     97       1790233658  208100000X         26     5501017928           1   \n",
       "4    106       1316495229  174H00000X         13       2013-211           1   \n",
       "\n",
       "          npi  last_name first_name middle_name prefix suffix  \\\n",
       "0  1487102463     FINLEY   MARIANNA         NaN    NaN    NaN   \n",
       "1  1033667035      OXLEY      MEGAN     FRANCES    MS.    NaN   \n",
       "2  1225586258   SISNEROS   CONTESSA         NaN    NaN    NaN   \n",
       "3  1790233658  SCHLEMMER      AMBER           M    NaN    NaN   \n",
       "4  1316495229      TERRY      KATIE         NaN    NaN    NaN   \n",
       "\n",
       "   credential_text is_sole_proprietor sex  \\\n",
       "0              LPC               True   F   \n",
       "1  M.ED., LAT, ATC               True   F   \n",
       "2             PA-C               True   F   \n",
       "3              DPT               True   F   \n",
       "4              CLD               True   F   \n",
       "\n",
       "                            13872713232                          idindividual  \n",
       "0  31c1b247-83da-440a-bc7a-2673f1591bcd  3723eac5-b768-4444-bd71-c7bbcc1aba4f  \n",
       "1  bcf58541-7423-4597-8a03-409ddfba52a5  b3e06dd5-a15b-49f4-a0e7-d630638841ad  \n",
       "2  83241ffe-6823-4ba1-812b-2e88ca3bc8e8  8f61bd63-b033-4feb-a628-ed9cd87c260e  \n",
       "3  faa6fa37-e51d-4cf8-86e1-134775d16ba3  9d1a3887-2482-410f-a4db-d5a2378d9abc  \n",
       "4  c5e07e17-22cc-4c57-9150-10d85390e296  6a281cb1-a4e3-4403-b04a-806c5163de1e  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_taxonomy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49eaac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c78543",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'organizaiton_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m organization_df.rename(columns={\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mold_org_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mparent_id\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mold_parent_id\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m organization_df[\u001b[33m'\u001b[39m\u001b[33morg_id\u001b[39m\u001b[33m'\u001b[39m] = [uuid.uuid4() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m organization_df.index]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m organization_df[\u001b[33m'\u001b[39m\u001b[33morg_parent_id\u001b[39m\u001b[33m'\u001b[39m] = [organization_df.loc[organization_df[\u001b[33m'\u001b[39m\u001b[33mold_org_id\u001b[39m\u001b[33m'\u001b[39m]==x[\u001b[33m'\u001b[39m\u001b[33mold_parent_id\u001b[39m\u001b[33m'\u001b[39m]][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33morg_id\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43morganizaiton_df\u001b[49m]\n\u001b[32m      6\u001b[39m organization_df[\u001b[33m'\u001b[39m\u001b[33morg_parent_id\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m organization_npi_df = df_dict[\u001b[33m'\u001b[39m\u001b[33morganization_npi.csv\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'organizaiton_df' is not defined"
     ]
    }
   ],
   "source": [
    "organization_df = df_dict['organization.csv']\n",
    "organization_df['is_primary'] = True\n",
    "organization_df.rename(columns={'id':'old_org_id', 'parent_id':'old_parent_id'}, inplace=True)\n",
    "organization_df['org_id'] = [uuid.uuid4() for i in organization_df.index]\n",
    "organization_df.set_index('old_org_id', inplace=True)\n",
    "organization_df['org_parent_id'] = [organization_df['old_parent_id'].apply(lambda x: organization_df.loc[x]['org_id'])]\n",
    "organization_npi_df = df_dict['organization_npi.csv']\n",
    "organization_npi_df.rename(columns={'organization_id':'old_org_id'}, inplace=True)\n",
    "organization_npi_df['id'] = [uuid.uuid4() for i in organization_npi_df.index]\n",
    "npi2 = organization_npi_df[['npi']]\n",
    "npi2['entity_type_code'] = 2\n",
    "merged_organization_df = organization_npi_df.merge(organization_df, on='old_org_id')\n",
    "merged_organization_df.rename(columns={'org_id':'parent_id'}, inplace=True)\n",
    "organization_df.rename(columns = {'org_id':'id', 'org_parent_id': 'parent_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_df = pd.concat([npi1,npi2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a319ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_df = df_dict['endpoint.csv']\n",
    "endpoint_df.rename(columns={'id':'endpoint_id'})\n",
    "ehr_vendor_df = endpoint_df[['vendor_name']].drop_duplicates()\n",
    "ehr_vendor_df['id'] = [uuid.uuid4() for i in ehr_vendor_df.index]\n",
    "ehr_vendor_df.rename(columns={'vendor_name':'name'}, inplace=True)\n",
    "ehr_vendor_df.set_index('vendor_name', inplace=True)\n",
    "endpoint_df['ehr_vendor_id'] = endpoint_df['vendor_name'].apply(lambda x: ehr_vendor_df.loc[x]['id'])\n",
    "endpoint_df['environment_type_id'] = 'prod'\n",
    "endpoint_df['endpoint_connection_type_id'] = 'hl7-fhir-rest'\n",
    "endpoint_df['id'] = [uuid.uuid4() for i in endpoint_df.index]\n",
    "endpoint_df.rename(columns={'fhir_url':'address'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_to_endpoint_df = df_dict['organization_endpoint.csv']\n",
    "merged_org_to_endpoint_df = org_to_endpoint_df.merge(endpoint_df, on = 'endpoint_id').merge(organization_npi_df, left_on = 'organization_npi', right_on = 'npi', suffix = ('endpoint', 'organization'))\n",
    "merged_org_to_endpoint_df= merged_org_to_endpoint_df[['idendpoint', 'idorganization']].rename(columns = {'idendpoint': 'endpoint_instance_id', 'idorganization':'organization_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56004b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df = df_dict['location.csv']\n",
    "address_df.rename(columns={'id':'address_us_id', 'line':'delivery_line_1', 'postalcode':'zipcode'}, inplace=True)\n",
    "address_df['id']= [uuid.uuid4() for i in address_df.index]\n",
    "address_df['state_code'] = address_df['state'].apply(lambda x: fips_state_df.loc[x]['id'])\n",
    "location_npi_df = df_dict['location_npi.csv']\n",
    "merged_location_df = location_npi_df.merge(address_df, left_on='address_us_id', right_on = 'location_id').merge(npi_df,practitioner_df,organization_df, on = 'npi', suffixes=('npi','individual','organization'))\n",
    "merged_location_df.rename(columns={'id':'address_id', 'idindividual':'individual_id', 'idorganization':'organization_id'}, inplace=True)\n",
    "merged_location_df['address_use_id'] = 2\n",
    "individual_to_address_df = merged_location_df[['address_id','individual_id', 'address_use_id']].dropna(how='any')\n",
    "location_df = merged_location_df[['address_id','organization_id','name', 'address_use_id']].dropna(how='any')\n",
    "location_df['id'] = [uuid.uuid4() for i in location_df.index]\n",
    "location_to_endpoint_df = location_df.merge(org_to_endpoint_df, on = 'organization_id')[['id', 'endpoint_id']].dropna(how = 'any').rename(columns = {'id':'location_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_to_organization_df = df_dict['personal_npi_to_organizational_npi.csv']\n",
    "merged_provider_to_org_df = provider_to_organization_df.merge(practitioner_df, left_on = 'personal_npi', right_on = 'npi').merge(merged_organization_df, left_on = 'organizational_npi', right_on = 'npi', suffixes = ('individual', 'organization'))\n",
    "merged_provider_to_org_df.rename(columns = {'idindividual':'individual_id', 'idorganization':'organization_id'}, inplace=True)\n",
    "merged_provider_to_org_df['id'] = [uuid.uuid4() for i in merged_provider_to_org_df.index]\n",
    "merged_provider_to_org_df['relationship_type_id'] = 2\n",
    "provider_to_location_df = merged_provider_to_org_df.merge(location_df, on='organization_id')\n",
    "provider_to_location_df['id'] = [uuid.uuid4() for i in provider_to_location_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = 'npd'\n",
    "load = False\n",
    "\n",
    "# load npi\n",
    "show_or_load(npi_df, 'npi', schema_name, load)\n",
    "\n",
    "# load individual\n",
    "show_or_load(practitioner_df[['id', 'sex']], 'individual', schema_name, load)\n",
    "\n",
    "practitioner_df.rename(columns={'id':'individual_id'}, inplace=True)\n",
    "\n",
    "# load individual_to_name\n",
    "show_or_load(practitioner_df[['individual_id', 'first_name', 'middle_name', 'last_name', 'prefix', 'suffix']], 'individual', schema_name, load)\n",
    "\n",
    "# load provider\n",
    "show_or_load(practitioner_df[['npi', 'individual_id']], 'provider', schema_name, load)\n",
    "\n",
    "# load organization\n",
    "show_or_load(organization_df[['id', 'parent_id']], 'organization', schema_name, load)\n",
    "show_or_load(merged_organization_df[['id', 'parent_id']], 'organization', schema_name, load)\n",
    "\n",
    "organization_df.rename(columns={'id':'organization_id'}, inplace=True)\n",
    "merged_organization_df.rename(columns={'id':'organization_id'}, inplace=True)\n",
    "\n",
    "# load organization_to_name\n",
    "show_or_load(organization_df[['organization_id', 'name', 'is_primary']], 'organization_to_name', schema_name, load)\n",
    "show_or_load(merged_organization_df[['organization_id', 'name', 'is_primary']], 'organization_to_name', schema_name, load)\n",
    "\n",
    "# load clinical_organization\n",
    "show_or_load(merged_organization_df[['organization_id', 'npi']], 'clinical_organization', schema='npd', con = engine)\n",
    "\n",
    "# load ehr_vendor\n",
    "show_or_load(ehr_vendor_df[['id', 'name']], 'ehr_vendor', schema_name, load)\n",
    "\n",
    "# load endpoint_instance\n",
    "show_or_load(endpoint_df[['id', 'ehr_vendor_id', 'address', 'endpoint_connection_type_id', 'environment_type_id']], 'endpoint_instance', schema_name, load)\n",
    "\n",
    "# load address_us\n",
    "show_or_load(location_df[['address_us_id', 'delivery_line_1','city','state_code','zipcode']].rename(columns={'address_us_id':'id'}), 'address_us', schema_name, load)\n",
    "\n",
    "# load address\n",
    "show_or_load(location_df[['id', 'address_us_id']], 'address', schema_name, load)\n",
    "\n",
    "# load individual_to_address\n",
    "show_or_load(individual_to_address_df, 'individual_to_address', schema_name, load)\n",
    "\n",
    "# load organization_to_address\n",
    "show_or_load(location_df[['address_id','organization_id']], 'organization_to_address', schema_name, load)\n",
    "\n",
    "# load location\n",
    "show_or_load(location_df[['id','address_id','organization_id']], 'location', schema_name, load)\n",
    "\n",
    "# load location_to_endpoint\n",
    "show_or_load(location_to_endpoint_df, 'location_to_endpoint', schema_name, load)\n",
    "\n",
    "# load provider_to_organization\n",
    "show_or_load(merged_provider_to_org_df.dropna(how='any'), 'provider_to_organization', schema_name, load)\n",
    "\n",
    "# load provider_to_location\n",
    "show_or_load(provider_to_location_df.dropna(how='any'), 'provider_to_location', schema_name, load)\n",
    "\n",
    "# load provider_to_taxonomy\n",
    "show_or_load(dedup_taxonomy_df, 'provider_to_taxonomy', schema_name, load)\n",
    "\n",
    "# load provider_to_credential\n",
    "show_or_load(credential_df[['license_number', 'state_code', 'provider_to_taxonomy_id']], 'provider_to_taxonomy', schema_name, load)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
