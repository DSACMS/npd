{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a26a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dbHelpers import createEngine\n",
    "import uuid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09f9d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = createEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../scratch/halloween_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d13c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_state_df = pd.read_sql('select * from npd.fips_state', con = engine)\n",
    "fips_state_df.set_index('abbreviation', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96301a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_or_load(df, table_name, schema_name, load=False):\n",
    "    if load:\n",
    "        df.to_sql(table_name, schema = schema_name, con = engine)\n",
    "    else:\n",
    "        df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9f97bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_to_bool = {1: True, 0: False}\n",
    "\n",
    "\n",
    "def convertBool(val):\n",
    "    if val in primary_to_bool.keys():\n",
    "        return primary_to_bool[val]\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def val_or_nan(df, index, column):\n",
    "    if index in df.index:\n",
    "        return df.loc[index][column]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ed4a504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/3752938139.py:5: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,f))\n"
     ]
    }
   ],
   "source": [
    "df_dict={}\n",
    "for f in os.listdir(path):\n",
    "    if '.csv' in f:\n",
    "        tablename = f.split('.csv')[0]\n",
    "        df = pd.read_csv(os.path.join(path,f))\n",
    "        df_dict[f]=df\n",
    "        #df.to_sql(tablename, index=False, schema = 'raw_csv', con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e520af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/3830421139.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  npi1['entity_type_code'] = 1\n",
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/3830421139.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  provider_to_taxonomy_df['is_primary'] = provider_to_taxonomy_df['is_primary'].apply(lambda x: convertBool(x))\n"
     ]
    }
   ],
   "source": [
    "practitioner_df = df_dict['practitioner.csv']\n",
    "#note: we can do this because each practitioner only appears once in this table\n",
    "practitioner_df['id'] = [uuid.uuid4() for i in practitioner_df.index]\n",
    "practitioner_df_renamed = practitioner_df.rename(columns = {'gender_code': 'sex', 'name_prefix': 'prefix', 'name_suffix': 'suffix'})\n",
    "npi_type1_df = practitioner_df_renamed[['npi']]\n",
    "npi_type1_df['entity_type_code'] = 1\n",
    "practitioner_taxonomy_df = df_dict['practitionerrole.csv']\n",
    "merged_taxonomy_df = practitioner_taxonomy_df.merge(practitioner_df_renamed, left_on = 'practitioner_id', right_on = 'npi', suffixes = ('tax', 'individual'), how='outer') \n",
    "merged_taxonomy_df = merged_taxonomy_df.loc[merged_taxonomy_df['state_code']!='ZZ']\n",
    "merged_taxonomy_df['state_code'] = merged_taxonomy_df['state_code'].apply(lambda x: val_or_nan(fips_state_df, x, 'id'))\n",
    "merged_taxonomy_df_renamed = merged_taxonomy_df.rename(columns={'idindividual': 'individual_id', 'taxonomy_code':'nucc_code'})\n",
    "provider_to_taxonomy_df = merged_taxonomy_df_renamed[['individual_id', 'nucc_code', 'is_primary']]\n",
    "provider_to_taxonomy_df['is_primary'] = provider_to_taxonomy_df['is_primary'].apply(lambda x: convertBool(x))\n",
    "dedup_taxonomy_df = provider_to_taxonomy_df.sort_values(by='is_primary', ascending=False)[\n",
    "        ['individual_id', 'nucc_code', 'is_primary']].drop_duplicates(subset=['nucc_code', 'individual_id'])\n",
    "dedup_taxonomy_df['id'] = [uuid.uuid4() for i in dedup_taxonomy_df.index]\n",
    "credential_df = provider_to_taxonomy_df.merge(dedup_taxonomy_df, on = ['individual_id', 'nucc_code'], suffixes = ('tax', 'cred'), how='outer')\n",
    "credential_df_renamed = credential_df.rename(columns={'idtax': 'provider_to_taxonomy_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c78543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/457121493.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  npi2['entity_type_code'] = 2\n"
     ]
    }
   ],
   "source": [
    "organization_df = df_dict['organization.csv']\n",
    "organization_df['is_primary'] = True\n",
    "organization_df_renamed = organization_df.rename(columns={'id':'old_org_id', 'parent_id':'old_parent_id', 'organization_name':'name'})\n",
    "organization_df_renamed['org_id'] = [uuid.uuid4() for i in organization_df_renamed.index]\n",
    "organization_df_renamed['org_parent_id'] = organization_df_renamed['old_parent_id'].apply(lambda x: val_or_nan(organization_df_renamed, x, 'org_id'))\n",
    "organization_npi_df = df_dict['organization_npi.csv']\n",
    "organization_npi_df_renamed = organization_npi_df.rename(columns={'organization_id':'old_org_id'})\n",
    "organization_npi_df_renamed['id'] = [uuid.uuid4() for i in organization_npi_df_renamed.index]\n",
    "npi_type2_df = organization_npi_df_renamed[['npi']]\n",
    "npi_type2_df['entity_type_code'] = 2\n",
    "clinical_organization_df = organization_npi_df_renamed.merge(organization_df_renamed, on='old_org_id', how='outer')\n",
    "clinical_organization_df_renamed = clinical_organization_df.rename(columns={'org_id':'parent_id'})\n",
    "other_organization_df = organization_df.rename(columns = {'org_id':'id', 'org_parent_id': 'parent_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_df = pd.concat([npi_type1_df,npi_type2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a319ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/4021398828.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ehr_vendor_df['id'] = [uuid.uuid4() for i in ehr_vendor_df.index]\n",
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/4021398828.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ehr_vendor_df.rename(columns={'vendor_name':'name'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "endpoint_df = df_dict['endpoint.csv']\n",
    "endpoint_df_renamed = endpoint_df.rename(columns={'id':'endpoint_id','fhir_url':'address'})\n",
    "ehr_vendor_df = endpoint_df.drop_duplicates(subset='vendor_name')\n",
    "ehr_vendor_df['id'] = [uuid.uuid4() for i in ehr_vendor_df.index]\n",
    "ehr_vendor_df_renamed = ehr_vendor_df.rename(columns={'vendor_name':'name'})\n",
    "ehr_vendor_df_renamed.set_index('name', inplace=True)\n",
    "endpoint_df_renamed['ehr_vendor_id'] = endpoint_df_renamed['vendor_name'].apply(lambda x: ehr_vendor_df_renamed.loc[x]['id'])\n",
    "endpoint_df_renamed['environment_type_id'] = 'prod'\n",
    "endpoint_df_renamed['endpoint_connection_type_id'] = 'hl7-fhir-rest'\n",
    "endpoint_df_renamed['id'] = [uuid.uuid4() for i in endpoint_df_renamed.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_to_endpoint_df = df_dict['organization_endpoint.csv']\n",
    "merged_org_to_endpoint_df = org_to_endpoint_df.merge(endpoint_df_renamed, on = 'endpoint_id', how='outer').merge(clinical_organization_df_renamed, left_on = 'organization_npi', right_on = 'npi', suffixes = ('endpoint', 'organization'), how='outer')\n",
    "merged_org_to_endpoint_df= merged_org_to_endpoint_df[['idendpoint', 'idorganization']].rename(columns = {'idendpoint': 'endpoint_instance_id', 'idorganization':'organization_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56004b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/2780095897.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  address_df['state_code'] = address_df['state'].apply(lambda x: fips_state_df.loc[x]['id'])\n"
     ]
    }
   ],
   "source": [
    "address_df = df_dict['location.csv']\n",
    "address_df_renamed = address_df.rename(columns={'id':'address_us_id', 'line':'delivery_line_1', 'postalcode':'zipcode'})\n",
    "address_df_renamed['id']= [uuid.uuid4() for i in address_df_renamed.index]\n",
    "address_df_renamed = address_df_renamed.loc[(address_df_renamed['state'] != 'FM') & (address_df_renamed['state'] != '~') & (address_df_renamed['state'] != 'UK') & (address_df['state'] != 'MH')]\n",
    "address_df_renamed['state_code'] = address_df_renamed['state'].apply(lambda x: fips_state_df.loc[x]['id'])\n",
    "location_npi_df = df_dict['npi_location.csv']\n",
    "merged_df_1 = location_npi_df.merge(address_df_renamed, left_on='location_id', right_on = 'address_us_id', how='outer')\n",
    "merged_df_2 = merged_df_1.merge(npi_df, on = 'npi', suffixes=('address','npi'), how='outer')\n",
    "merged_df_3 = merged_df_2.merge(practitioner_df_renamed, on = 'npi', suffixes = ('address', 'individual'), how='outer')\n",
    "merged_location_df = merged_df_3.merge(clinical_organization_df_renamed, on = 'npi', suffixes = ('address', 'organization'), how='outer')\n",
    "merged_location_df_renamed = merged_location_df.rename(columns={'idaddress':'address_id', 'idindividual':'individual_id', 'id':'organization_id', 'nameaddress':'name'})\n",
    "merged_location_df_renamed['address_use_id'] = 2\n",
    "individual_to_address_df = merged_location_df_renamed[['address_id','individual_id', 'address_use_id']].dropna(how='any')\n",
    "location_df = merged_location_df_renamed[['address_id','organization_id','name', 'address_use_id']].dropna(how='any')\n",
    "location_df['id'] = [uuid.uuid4() for i in location_df.index]\n",
    "location_to_endpoint_df = location_df.merge(merged_org_to_endpoint_df, on = 'organization_id', how='outer')[['id', 'endpoint_instance_id']].dropna(how = 'any').rename(columns = {'id':'location_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_to_organization_df = df_dict['personal_npi_to_organizational_npi.csv']\n",
    "merged_provider_to_org_df = provider_to_organization_df.merge(practitioner_df_renamed, left_on = 'personal_npi', right_on = 'npi', how='outer').merge(clinical_organization_df_renamed, left_on = 'organizational_npi', right_on = 'npi', suffixes = ('individual', 'organization'), how='outer')\n",
    "provider_to_org_df_renamed = merged_provider_to_org_df.rename(columns = {'idindividual':'individual_id', 'idorganization':'organization_id'})\n",
    "provider_to_org_df_renamed['id'] = [uuid.uuid4() for i in provider_to_org_df_renamed.index]\n",
    "provider_to_org_df_renamed['relationship_type_id'] = 2\n",
    "provider_to_location_df = provider_to_org_df_renamed.merge(location_df, on='organization_id', how='outer')\n",
    "provider_to_location_df['id'] = [uuid.uuid4() for i in provider_to_location_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bb0b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[159]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m show_or_load(npi_df, \u001b[33m'\u001b[39m\u001b[33mnpi\u001b[39m\u001b[33m'\u001b[39m, schema_name, load)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# load individual\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m show_or_load(\u001b[43mpractitioner_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msex\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mindividual\u001b[39m\u001b[33m'\u001b[39m, schema_name, load)\n\u001b[32m     10\u001b[39m practitioner_df.rename(columns={\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mindividual_id\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# load individual_to_name\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['id'] not in index\""
     ]
    }
   ],
   "source": [
    "schema_name = 'npd'\n",
    "load = False\n",
    "\n",
    "# load npi\n",
    "show_or_load(npi_df, 'npi', schema_name, load)\n",
    "\n",
    "# load individual\n",
    "show_or_load(practitioner_df_renamed[['id', 'sex']], 'individual', schema_name, load)\n",
    "\n",
    "practitioner_df_renamed_renamed = practitioner_df_renamed.rename(columns={'id':'individual_id'})\n",
    "\n",
    "# load individual_to_name\n",
    "show_or_load(practitioner_df_renamed_renamed[['individual_id', 'first_name', 'middle_name', 'last_name', 'prefix', 'suffix']], 'individual', schema_name, load)\n",
    "\n",
    "# load provider\n",
    "show_or_load(practitioner_df_renamed_renamed[['npi', 'individual_id']], 'provider', schema_name, load)\n",
    "\n",
    "# load organization\n",
    "show_or_load(other_organization_df[['id', 'parent_id']], 'organization', schema_name, load)\n",
    "show_or_load(clinical_organization_df_renamed[['id', 'parent_id']], 'organization', schema_name, load)\n",
    "\n",
    "other_organization_df_renamed = other_organization_df.rename(columns={'id':'organization_id'}, inplace=True)\n",
    "clinical_organization_df_renamed_renamed = clinical_organization_df_renamed.rename(columns={'id':'organization_id'}, inplace=True)\n",
    "\n",
    "# load organization_to_name\n",
    "show_or_load(other_organization_df_renamed[['organization_id', 'name', 'is_primary']], 'organization_to_name', schema_name, load)\n",
    "show_or_load(clinical_organization_df_renamed_renamed[['organization_id', 'name', 'is_primary']], 'organization_to_name', schema_name, load)\n",
    "\n",
    "# load clinical_organization\n",
    "show_or_load(clinical_organization_df_renamed_renamed[['organization_id', 'npi']], 'clinical_organization', schema_name, load)\n",
    "\n",
    "# load ehr_vendor\n",
    "show_or_load(ehr_vendor_df_renamed[['id', 'name']], 'ehr_vendor', schema_name, load)\n",
    "\n",
    "# load endpoint_instance\n",
    "show_or_load(endpoint_df_renamed[['id', 'ehr_vendor_id', 'address', 'endpoint_connection_type_id', 'environment_type_id']], 'endpoint_instance', schema_name, load)\n",
    "\n",
    "# load address_us\n",
    "show_or_load(address_df_renamed[['address_us_id', 'delivery_line_1','city','state_code','zipcode']].rename(columns={'address_us_id':'id'}), 'address_us', schema_name, load)\n",
    "\n",
    "# load address\n",
    "show_or_load(location_df[['id', 'address_us_id']], 'address', schema_name, load)\n",
    "\n",
    "# load individual_to_address\n",
    "show_or_load(individual_to_address_df, 'individual_to_address', schema_name, load)\n",
    "\n",
    "# load organization_to_address\n",
    "show_or_load(location_df[['address_id','organization_id']], 'organization_to_address', schema_name, load)\n",
    "\n",
    "# load location\n",
    "show_or_load(location_df[['id','address_id','organization_id']], 'location', schema_name, load)\n",
    "\n",
    "# load location_to_endpoint\n",
    "show_or_load(location_to_endpoint_df, 'location_to_endpoint', schema_name, load)\n",
    "\n",
    "# load provider_to_organization\n",
    "show_or_load(provider_to_org_df_renamed.dropna(how='any'), 'provider_to_organization', schema_name, load)\n",
    "\n",
    "# load provider_to_location\n",
    "show_or_load(provider_to_location_df.dropna(how='any'), 'provider_to_location', schema_name, load)\n",
    "\n",
    "# load provider_to_taxonomy\n",
    "show_or_load(dedup_taxonomy_df, 'provider_to_taxonomy', schema_name, load)\n",
    "\n",
    "# load provider_to_credential\n",
    "show_or_load(credential_df_renamed[['license_number', 'state_code', 'provider_to_taxonomy_id']], 'provider_to_taxonomy', schema_name, load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a8d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
