{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a26a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dbHelpers import createEngine\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f9d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = createEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e78049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../scratch/halloween_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d13c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_state_df = pd.read_sql('select * from npd.fips_state', con = engine)\n",
    "fips_state_df.set_index('abbreviation', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed4a504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_11117/2424709856.py:5: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,f))\n"
     ]
    }
   ],
   "source": [
    "df_dict={}\n",
    "for f in os.listdir(path):\n",
    "    if '.csv' in f:\n",
    "        tablename = f.split('.csv')[0]\n",
    "        df = pd.read_csv(os.path.join(path,f))\n",
    "        df_dict[f]=df\n",
    "        df.to_sql(tablename, index=False, schema = 'raw_csv', con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e520af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "practitioner_df = df_dict['practitioner.csv']\n",
    "#note: we can do this because each practitioner only appears once in this table\n",
    "practitioner_df[id] = [uuid.uuid4() for i in practitioner_df.index]\n",
    "practitioner_df.set_index('id', inplace=True)\n",
    "practitioner_df.rename(columns = {'gender_code': 'sex', 'name_prefix': 'prefix', 'name_suffix': 'suffix'}, inplace=True)\n",
    "npi1 = practitioner_df[['npi']]\n",
    "npi1['entity_type_code'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c78543",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'organizaiton_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m organization_df.rename(columns={\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mold_org_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mparent_id\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mold_parent_id\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m organization_df[\u001b[33m'\u001b[39m\u001b[33morg_id\u001b[39m\u001b[33m'\u001b[39m] = [uuid.uuid4() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m organization_df.index]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m organization_df[\u001b[33m'\u001b[39m\u001b[33morg_parent_id\u001b[39m\u001b[33m'\u001b[39m] = [organization_df.loc[organization_df[\u001b[33m'\u001b[39m\u001b[33mold_org_id\u001b[39m\u001b[33m'\u001b[39m]==x[\u001b[33m'\u001b[39m\u001b[33mold_parent_id\u001b[39m\u001b[33m'\u001b[39m]][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33morg_id\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43morganizaiton_df\u001b[49m]\n\u001b[32m      6\u001b[39m organization_df[\u001b[33m'\u001b[39m\u001b[33morg_parent_id\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m organization_npi_df = df_dict[\u001b[33m'\u001b[39m\u001b[33morganization_npi.csv\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'organizaiton_df' is not defined"
     ]
    }
   ],
   "source": [
    "organization_df = df_dict['organization.csv']\n",
    "organization_df['is_primary'] = True\n",
    "organization_df.rename(columns={'id':'old_org_id', 'parent_id':'old_parent_id'}, inplace=True)\n",
    "organization_df['org_id'] = [uuid.uuid4() for i in organization_df.index]\n",
    "organization_df.set_index('old_org_id', inplace=True)\n",
    "organization_df['org_parent_id'] = [organization_df['old_parent_id'].apply(lambda x: organization_df.loc[x]['org_id'])]\n",
    "organization_npi_df = df_dict['organization_npi.csv']\n",
    "organization_npi_df.rename(columns={'organization_id':'old_org_id'}, inplace=True)\n",
    "organization_npi_df['id'] = [uuid.uuid4() for i in organization_npi_df.index]\n",
    "npi2 = organization_npi_df[['npi']]\n",
    "npi2['entity_type_code'] = 2\n",
    "merged_organization_df = organization_npi_df.merge(organization_df, on='old_org_id')\n",
    "merged_organization_df.rename(columns={'org_id':'parent_id'}, inplace=True)\n",
    "organization_df.rename(columns = {'org_id':'id', 'org_parent_id': 'parent_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_df = pd.concat([npi1,npi2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a319ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_df = df_dict['endpoint.csv']\n",
    "ehr_vendor_df = endpoint_df[['vendor_name']].drop_duplicates()\n",
    "ehr_vendor_df['id'] = [uuid.uuid4() for i in ehr_vendor_df.index]\n",
    "ehr_vendor_df.rename(columns={'vendor_name':'name'}, inplace=True)\n",
    "ehr_vendor_df.set_index('vendor_name', inplace=True)\n",
    "endpoint_df['ehr_vendor_id'] = endpoint_df['vendor_name'].apply(lambda x: ehr_vendor_df.loc[x]['id'])\n",
    "endpoint_df['environment_type_id'] = 'prod'\n",
    "endpoint_df['endpoint_connection_type_id'] = 'hl7-fhir-rest'\n",
    "endpoint_df['id'] = [uuid.uuid4() for i in endpoint_df.index]\n",
    "endpoint_df.rename(columns={'fhir_url':'address'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_to_organization_df = df_dict['organization_endpoint.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56004b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df = df_dict['location.csv']\n",
    "address_df.rename(columns={'id':'address_us_id', 'line':'delivery_line_1', 'postalcode':'zipcode'}, inplace=True)\n",
    "address_df['id']= [uuid.uuid4() for i in address_df.index]\n",
    "address_df['state_code'] = address_df['state'].apply(lambda x: fips_state_df.loc[x]['id'])\n",
    "location_npi_df = df_dict['location_npi.csv']\n",
    "merged_location_df = location_npi_df.merge(address_df, left_on='address_us_id', right_on = 'location_id').merge(npi_df,practitioner_df,organization_df, on = 'npi', suffixes=('npi','individual','organization'))\n",
    "merged_location_df.rename(columns={'id':'address_id', 'id_individual':'individual_id', 'id_organization':'organization_id'}, inplace=True)\n",
    "merged_location_df['address_use_id'] = 2\n",
    "individual_to_address_df = merged_location_df[['address_id','individual_id', 'address_use_id']].dropna(how='any')\n",
    "location_df = merged_location_df[['address_id','organization_id','name', 'address_use_id']].dropna(how='any')\n",
    "location_df['id'] = [uuid.uuid4() for i in location_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595c9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8bb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load npi\n",
    "npi_df.to_sql('npi', schema = 'npd', con = engine)\n",
    "\n",
    "# load individual\n",
    "practitioner_df[['id', 'sex']].to_sql('individual', schema = 'npd', con = engine)\n",
    "\n",
    "practitioner_df.rename(columns={'id':'individual_id'}, inplace=True)\n",
    "\n",
    "# load individual_to_name\n",
    "practitioner_df[['individual_id', 'first_name', 'middle_name', 'last_name', 'prefix', 'suffix']].to_sql('individual', schema = 'npd', con = engine)\n",
    "\n",
    "# load provider\n",
    "practitioner_df[['npi', 'individual_id']].to_sql('provider', schema='npd', con=engine)\n",
    "\n",
    "# load organization\n",
    "organization_df[['id', 'parent_id']].to_sql('organization', schema='npd', con=engine)\n",
    "merged_organization_df[['id', 'parent_id']].to_sql('organization', schema='npd', con=engine)\n",
    "\n",
    "organization_df.rename(columns={'id':'organization_id'}, inplace=True)\n",
    "merged_organization_df.rename(columns={'id':'organization_id'}, inplace=True)\n",
    "\n",
    "# load organization_to_name\n",
    "organization_df[['organization_id', 'name', 'is_primary']].to_sql('organization_to_name', schema = 'npd', con = engine)\n",
    "merged_organization_df[['organization_id', 'name', 'is_primary']].to_sql('organization_to_name', schema = 'npd', con = engine)\n",
    "\n",
    "# load clinical_organization\n",
    "merged_organization_df[['organization_id', 'npi']].to_sql('clinical_organization', schema='npd', con = engine)\n",
    "\n",
    "# load ehr_vendor\n",
    "ehr_vendor_df[['id', 'name']].to_sql('ehr_vendor', schema = 'npd', con = engine)\n",
    "\n",
    "# load endpoint_instance\n",
    "endpoint_df[['id', 'ehr_vendor_id', 'address', 'endpoint_connection_type_id', 'environment_type_id']].to_sql('endpoint_instance', schema = 'npd', con = engine)\n",
    "\n",
    "# load address_us\n",
    "location_df[['address_us_id', 'delivery_line_1','city','state_code','zipcode']].rename(columns={'address_us_id':'id'}).to_sql('address_us', schema = 'npd', con = engine)\n",
    "\n",
    "# load address\n",
    "location_df[['id', 'address_us_id']].to_sql('address', schema = 'npd', con = engine)\n",
    "\n",
    "# load individual_to_address\n",
    "individual_to_address_df.to_sql('individual_to_address', schema = 'npd', con = engine)\n",
    "\n",
    "# load organization_to_address\n",
    "location_df[['address_id','organization_id']].to_sql('organization_to_address', schema = 'npd', con = engine)\n",
    "\n",
    "# load location\n",
    "location_df[['id','address_id','organization_id']].to_sql('location', schema = 'npd', con = engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
