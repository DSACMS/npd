{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a26a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dbHelpers import createEngine\n",
    "import uuid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f9d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = createEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e78049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../scratch/halloween_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d13c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_state_df = pd.read_sql('select * from npd.fips_state', con = engine)\n",
    "fips_state_df.set_index('abbreviation', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96301a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_or_load(df, table_name, schema_name, load=False):\n",
    "    if load:\n",
    "        df.to_sql(table_name, schema = schema_name, con = engine, if_exists='append')\n",
    "    else:\n",
    "        df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f97bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_to_bool = {1: True, 0: False}\n",
    "\n",
    "\n",
    "def convertBool(val):\n",
    "    if val in primary_to_bool.keys():\n",
    "        return primary_to_bool[val]\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def val_or_nan(df, index, column):\n",
    "    if index in df.index:\n",
    "        return df.loc[index][column]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed4a504c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_78621/3752938139.py:5: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(path,f))\n"
     ]
    }
   ],
   "source": [
    "df_dict={}\n",
    "for f in os.listdir(path):\n",
    "    if '.csv' in f:\n",
    "        tablename = f.split('.csv')[0]\n",
    "        df = pd.read_csv(os.path.join(path,f))\n",
    "        df_dict[f]=df\n",
    "        #df.to_sql(tablename, index=False, schema = 'raw_csv', con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e520af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_78621/883890984.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  npi_type1_df['entity_type_code'] = 1\n",
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_78621/883890984.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  provider_to_taxonomy_df['is_primary'] = provider_to_taxonomy_df['is_primary'].apply(lambda x: convertBool(x))\n"
     ]
    }
   ],
   "source": [
    "practitioner_df = df_dict['practitioner.csv']\n",
    "#note: we can do this because each practitioner only appears once in this table\n",
    "practitioner_df['id'] = [uuid.uuid4() for i in practitioner_df.index]\n",
    "practitioner_df_renamed = practitioner_df.rename(columns = {'gender_code': 'sex', 'name_prefix': 'prefix', 'name_suffix': 'suffix'})\n",
    "npi_type1_df = practitioner_df_renamed[['npi']]\n",
    "npi_type1_df['entity_type_code'] = 1\n",
    "practitioner_taxonomy_df = df_dict['practitionerrole.csv']\n",
    "merged_taxonomy_df = practitioner_taxonomy_df.merge(practitioner_df_renamed, left_on = 'practitioner_id', right_on = 'npi', suffixes = ('tax', 'individual')) \n",
    "merged_taxonomy_df = merged_taxonomy_df.loc[merged_taxonomy_df['state_code']!='ZZ']\n",
    "merged_taxonomy_df['state_code'] = merged_taxonomy_df['state_code'].apply(lambda x: val_or_nan(fips_state_df, x, 'id'))\n",
    "merged_taxonomy_df_renamed = merged_taxonomy_df.rename(columns={'idindividual': 'individual_id', 'taxonomy_code':'nucc_code'})\n",
    "provider_to_taxonomy_df = merged_taxonomy_df_renamed[['individual_id', 'nucc_code', 'is_primary']]\n",
    "provider_to_taxonomy_df['is_primary'] = provider_to_taxonomy_df['is_primary'].apply(lambda x: convertBool(x))\n",
    "dedup_taxonomy_df = provider_to_taxonomy_df.sort_values(by='is_primary', ascending=False)[\n",
    "        ['individual_id', 'nucc_code', 'is_primary']].drop_duplicates(subset=['nucc_code', 'individual_id'])\n",
    "dedup_taxonomy_df['id'] = [uuid.uuid4() for i in dedup_taxonomy_df.index]\n",
    "credential_df = provider_to_taxonomy_df.merge(merged_taxonomy_df_renamed, on = ['individual_id', 'nucc_code'], suffixes = ('tax', 'cred'))\n",
    "credential_df_renamed = credential_df.rename(columns={'idtax': 'provider_to_taxonomy_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c78543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_78621/1744409031.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  npi_type2_df['entity_type_code'] = 2\n"
     ]
    }
   ],
   "source": [
    "organization_df = df_dict['organization.csv']\n",
    "organization_df['is_primary'] = True\n",
    "organization_df_renamed = organization_df.rename(columns={'id':'old_org_id', 'parent_id':'old_parent_id', 'organization_name':'name'})\n",
    "organization_df_renamed['org_id'] = [uuid.uuid4() for i in organization_df_renamed.index]\n",
    "organization_df_renamed['org_parent_id'] = organization_df_renamed['old_parent_id'].apply(lambda x: val_or_nan(organization_df_renamed, x, 'org_id'))\n",
    "organization_npi_df = df_dict['organization_npi.csv']\n",
    "organization_npi_df_renamed = organization_npi_df.rename(columns={'organization_id':'old_org_id'})\n",
    "organization_npi_df_renamed['id'] = [uuid.uuid4() for i in organization_npi_df_renamed.index]\n",
    "npi_type2_df = organization_npi_df_renamed[['npi']]\n",
    "npi_type2_df['entity_type_code'] = 2\n",
    "clinical_organization_df = organization_npi_df_renamed.merge(organization_df_renamed, on='old_org_id', how='outer')\n",
    "clinical_organization_df_renamed = clinical_organization_df.rename(columns={'org_id':'parent_id'})\n",
    "other_organization_df = organization_df_renamed.rename(columns = {'org_id':'id', 'org_parent_id': 'parent_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97fb8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "npi_df = pd.concat([npi_type1_df,npi_type2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a319ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zt/jvxrh15j40sfz4x_sldwpck00000gp/T/ipykernel_78621/1730438011.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ehr_vendor_df['id'] = [uuid.uuid4() for i in ehr_vendor_df.index]\n"
     ]
    }
   ],
   "source": [
    "endpoint_df = df_dict['endpoint.csv']\n",
    "endpoint_df_renamed = endpoint_df.rename(columns={'id':'endpoint_id','fhir_url':'address'})\n",
    "ehr_vendor_df = endpoint_df.drop_duplicates(subset='vendor_name')\n",
    "ehr_vendor_df['id'] = [uuid.uuid4() for i in ehr_vendor_df.index]\n",
    "ehr_vendor_df_renamed = ehr_vendor_df.rename(columns={'vendor_name':'name'})\n",
    "ehr_vendor_df_renamed.set_index('name', inplace=True, drop=False)\n",
    "endpoint_df_renamed['ehr_vendor_id'] = endpoint_df_renamed['vendor_name'].apply(lambda x: ehr_vendor_df_renamed.loc[x]['id'])\n",
    "endpoint_df_renamed['environment_type_id'] = 'prod'\n",
    "endpoint_df_renamed['endpoint_connection_type_id'] = 'hl7-fhir-rest'\n",
    "endpoint_df_renamed['id'] = [uuid.uuid4() for i in endpoint_df_renamed.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f6e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_to_endpoint_df = df_dict['organization_endpoint.csv']\n",
    "merged_org_to_endpoint_df = org_to_endpoint_df.merge(endpoint_df_renamed, on = 'endpoint_id', how='outer').merge(clinical_organization_df_renamed, left_on = 'organization_npi', right_on = 'npi', suffixes = ('endpoint', 'organization'), how='outer')\n",
    "merged_org_to_endpoint_df= merged_org_to_endpoint_df[['idendpoint', 'idorganization']].rename(columns = {'idendpoint': 'endpoint_instance_id', 'idorganization':'organization_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56004b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_df = df_dict['location.csv']\n",
    "address_df_renamed = address_df.rename(columns={'id':'address_us_id', 'line':'delivery_line_1', 'postalcode':'zipcode'})\n",
    "address_df_renamed['id']= [uuid.uuid4() for i in address_df_renamed.index]\n",
    "address_df_renamed = address_df_renamed.loc[(address_df_renamed['state'] != 'FM') & (address_df_renamed['state'] != '~') & (address_df_renamed['state'] != 'UK') & (address_df['state'] != 'MH')]\n",
    "address_df_renamed['state_code'] = address_df_renamed['state'].apply(lambda x: fips_state_df.loc[x]['id'])\n",
    "location_npi_df = df_dict['npi_location.csv']\n",
    "merged_df_1 = location_npi_df.merge(address_df_renamed, left_on='location_id', right_on = 'address_us_id', how='outer')\n",
    "merged_df_2 = merged_df_1.merge(npi_df, on = 'npi', suffixes=('address','npi'), how='outer')\n",
    "merged_df_3 = merged_df_2.merge(practitioner_df_renamed, on = 'npi', suffixes = ('address', 'individual'), how='outer')\n",
    "merged_location_df = merged_df_3.merge(clinical_organization_df_renamed, on = 'npi', suffixes = ('address', 'organization'), how='outer')\n",
    "merged_location_df_renamed = merged_location_df.rename(columns={'idaddress':'address_id', 'idindividual':'individual_id', 'id':'organization_id', 'nameaddress':'name'})\n",
    "merged_location_df_renamed['address_use_id'] = 2\n",
    "individual_to_address_df = merged_location_df_renamed[['address_id','individual_id', 'address_use_id']].dropna(how='any')\n",
    "location_df = merged_location_df_renamed[['address_id','organization_id','name', 'address_use_id']].dropna(how='any')\n",
    "location_df['id'] = [uuid.uuid4() for i in location_df.index]\n",
    "location_to_endpoint_df = location_df.merge(merged_org_to_endpoint_df, on = 'organization_id', how='outer')[['id', 'endpoint_instance_id']].dropna(how = 'any').rename(columns = {'id':'location_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2595c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_to_organization_df = df_dict['personal_npi_to_organizational_npi.csv']\n",
    "merged_provider_to_org_df = provider_to_organization_df.merge(practitioner_df_renamed, left_on = 'personal_npi', right_on = 'npi', how='outer').merge(clinical_organization_df_renamed, left_on = 'organizational_npi', right_on = 'npi', suffixes = ('individual', 'organization'), how='outer')\n",
    "provider_to_org_df_renamed = merged_provider_to_org_df.rename(columns = {'idindividual':'individual_id', 'idorganization':'organization_id'})\n",
    "provider_to_org_df_renamed['id'] = [uuid.uuid4() for i in provider_to_org_df_renamed.index]\n",
    "provider_to_org_df_renamed['relationship_type_id'] = 2\n",
    "provider_to_location_df = provider_to_org_df_renamed.merge(location_df, on='organization_id', how='outer')\n",
    "provider_to_location_df['id'] = [uuid.uuid4() for i in provider_to_location_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be8bb0b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'npi' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m load = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# load npi\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mshow_or_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpi_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnpi\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# load individual\u001b[39;00m\n\u001b[32m      8\u001b[39m show_or_load(practitioner_df_renamed[[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msex\u001b[39m\u001b[33m'\u001b[39m]], \u001b[33m'\u001b[39m\u001b[33mindividual\u001b[39m\u001b[33m'\u001b[39m, schema_name, load)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mshow_or_load\u001b[39m\u001b[34m(df, table_name, schema_name, load)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mshow_or_load\u001b[39m(df, table_name, schema_name, load=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      5\u001b[39m         df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:3106\u001b[39m, in \u001b[36mNDFrame.to_sql\u001b[39m\u001b[34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[39m\n\u001b[32m   2908\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2909\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   2910\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3102\u001b[39m \u001b[33;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[32m   3103\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   3104\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[32m-> \u001b[39m\u001b[32m3106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3117\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:844\u001b[39m, in \u001b[36mto_sql\u001b[39m\u001b[34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    840\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument should be either a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    841\u001b[39m     )\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema=schema, need_transaction=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:2020\u001b[39m, in \u001b[36mSQLDatabase.to_sql\u001b[39m\u001b[34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m   1970\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1971\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   1972\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2016\u001b[39m \u001b[33;03m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[32m   2017\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2018\u001b[39m sql_engine = get_engine(engine)\n\u001b[32m-> \u001b[39m\u001b[32m2020\u001b[39m table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprep_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2030\u001b[39m total_inserted = sql_engine.insert_records(\n\u001b[32m   2031\u001b[39m     table=table,\n\u001b[32m   2032\u001b[39m     con=\u001b[38;5;28mself\u001b[39m.con,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2039\u001b[39m     **engine_kwargs,\n\u001b[32m   2040\u001b[39m )\n\u001b[32m   2042\u001b[39m \u001b[38;5;28mself\u001b[39m.check_case_sensitive(name=name, schema=schema)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:1924\u001b[39m, in \u001b[36mSQLDatabase.prep_table\u001b[39m\u001b[34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[39m\n\u001b[32m   1912\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a SQLAlchemy type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1914\u001b[39m table = SQLTable(\n\u001b[32m   1915\u001b[39m     name,\n\u001b[32m   1916\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1922\u001b[39m     dtype=dtype,\n\u001b[32m   1923\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1924\u001b[39m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/sql.py:988\u001b[39m, in \u001b[36mSQLTable.create\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exists():\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.if_exists == \u001b[33m\"\u001b[39m\u001b[33mfail\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTable \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m already exists.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.if_exists == \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    990\u001b[39m         \u001b[38;5;28mself\u001b[39m.pd_sql.drop_table(\u001b[38;5;28mself\u001b[39m.name, \u001b[38;5;28mself\u001b[39m.schema)\n",
      "\u001b[31mValueError\u001b[39m: Table 'npi' already exists."
     ]
    }
   ],
   "source": [
    "schema_name = 'npd'\n",
    "load = True\n",
    "\n",
    "# load npi\n",
    "show_or_load(npi_df, 'npi', schema_name, load)\n",
    "\n",
    "# load individual\n",
    "show_or_load(practitioner_df_renamed[['id', 'sex']], 'individual', schema_name, load)\n",
    "\n",
    "practitioner_df_renamed_renamed = practitioner_df_renamed.rename(columns={'id':'individual_id'})\n",
    "\n",
    "# load individual_to_name\n",
    "show_or_load(practitioner_df_renamed_renamed[['individual_id', 'first_name', 'middle_name', 'last_name', 'prefix', 'suffix']], 'individual', schema_name, load)\n",
    "\n",
    "# load provider\n",
    "show_or_load(practitioner_df_renamed_renamed[['npi', 'individual_id']], 'provider', schema_name, load)\n",
    "\n",
    "# load organization\n",
    "show_or_load(other_organization_df[['id', 'parent_id']], 'organization', schema_name, load)\n",
    "show_or_load(clinical_organization_df_renamed[['id', 'parent_id']], 'organization', schema_name, load)\n",
    "\n",
    "other_organization_df_renamed = other_organization_df.rename(columns={'id':'organization_id', 'organization_name':'name'})\n",
    "clinical_organization_df_renamed_renamed = clinical_organization_df_renamed.rename(columns={'id':'organization_id'})\n",
    "\n",
    "# load organization_to_name\n",
    "show_or_load(other_organization_df_renamed[['organization_id', 'name', 'is_primary']], 'organization_to_name', schema_name, load)\n",
    "show_or_load(clinical_organization_df_renamed_renamed[['organization_id', 'name', 'is_primary']], 'organization_to_name', schema_name, load)\n",
    "\n",
    "# load clinical_organization\n",
    "show_or_load(clinical_organization_df_renamed_renamed[['organization_id', 'npi']], 'clinical_organization', schema_name, load)\n",
    "\n",
    "# load ehr_vendor\n",
    "show_or_load(ehr_vendor_df_renamed[['id', 'name']], 'ehr_vendor', schema_name, load)\n",
    "\n",
    "# load endpoint_instance\n",
    "show_or_load(endpoint_df_renamed[['id', 'ehr_vendor_id', 'address', 'endpoint_connection_type_id', 'environment_type_id']], 'endpoint_instance', schema_name, load)\n",
    "\n",
    "# load address_us\n",
    "show_or_load(address_df_renamed[['address_us_id', 'delivery_line_1','city','state_code','zipcode']].rename(columns={'address_us_id':'id'}), 'address_us', schema_name, load)\n",
    "\n",
    "# load address\n",
    "show_or_load(address_df_renamed[['id', 'address_us_id']], 'address', schema_name, load)\n",
    "\n",
    "# load individual_to_address\n",
    "show_or_load(individual_to_address_df, 'individual_to_address', schema_name, load)\n",
    "\n",
    "# load organization_to_address\n",
    "show_or_load(location_df[['address_id','organization_id']], 'organization_to_address', schema_name, load)\n",
    "\n",
    "# load location\n",
    "show_or_load(location_df[['id','address_id','organization_id']], 'location', schema_name, load)\n",
    "\n",
    "# load location_to_endpoint\n",
    "show_or_load(location_to_endpoint_df, 'location_to_endpoint', schema_name, load)\n",
    "\n",
    "# load provider_to_organization\n",
    "show_or_load(provider_to_org_df_renamed.dropna(how='any'), 'provider_to_organization', schema_name, load)\n",
    "\n",
    "# load provider_to_location\n",
    "show_or_load(provider_to_location_df.dropna(how='any'), 'provider_to_location', schema_name, load)\n",
    "\n",
    "# load provider_to_taxonomy\n",
    "show_or_load(dedup_taxonomy_df, 'provider_to_taxonomy', schema_name, load)\n",
    "\n",
    "# load provider_to_credential\n",
    "show_or_load(credential_df_renamed[['license_number', 'state_code', 'provider_to_taxonomy_id']], 'provider_to_credential', schema_name, load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70442a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
